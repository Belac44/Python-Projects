{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab49334",
   "metadata": {},
   "source": [
    "### Eucledian Repesentation of the Email data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80a64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using PorterStemmer to do stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e36173",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdeb7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting hold of all the files in ham and spam folder in a list form\n",
    "all_ham_files = glob(\".\\ham\\*.txt\")\n",
    "all_spam_files = glob(\".\\spam\\*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f945ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to tokenize a email and stem it\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c04265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming all emails in ham folder to ham_stemmed\n",
    "\n",
    "for file_name in all_ham_files:\n",
    "    with open(file_name) as file:\n",
    "        data = file.read().replace(\"\\n\", \" \")\n",
    "        stemmed = stemSentence(data)\n",
    "        filename = file_name.split(\"\\\\\")[-1]\n",
    "        with open(f\"./ham_stemmed/{filename}\", \"w\") as stem:\n",
    "            stem.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d815bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming all emails in spam folder to spam_stemmed\n",
    "\n",
    "for file_name in all_spam_files:\n",
    "    with open(file_name, encoding='utf-8', errors='ignore' ) as file:\n",
    "        data = file.read().replace(\"\\n\", \" \")\n",
    "        stemmed = stemSentence(data)\n",
    "        filename = file_name.split(\"\\\\\")[-1]\n",
    "        with open(f\"./spam_stemmed/{filename}\", \"w\") as stem:\n",
    "            stem.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba4cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting hold of all files in ham_stemmed and spam_stemmed in a list\n",
    "ham_stemmed= glob(\".\\ham_stemmed\\*.txt\")\n",
    "spam_stemmed = glob(\".\\spam_stemmed\\*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb87126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50540"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a dictionary with all the words in all emails as key and a value of zero\n",
    "\n",
    "word_dict = {}\n",
    "\n",
    "for file_name in spam_stemmed + ham_stemmed:\n",
    "    with open(file_name, encoding='utf-8', errors='ignore' ) as file:\n",
    "        sentence = file.read()\n",
    "        words = word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            if word not in word_dict.keys():\n",
    "                word_dict[word] = 0\n",
    "                \n",
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff2f8ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a vector of words for each spam email\n",
    "\n",
    "spam_emails_vectors = {}\n",
    "\n",
    "for file in spam_stemmed:\n",
    "    with open(file) as file:\n",
    "        sentence = file.read()\n",
    "        words = word_tokenize(sentence)\n",
    "        email_word_dict = word_dict.copy()\n",
    "        for word in words:\n",
    "            email_word_dict[word] += 1\n",
    "        \n",
    "        spam_emails_vectors[file] = [value for key, value in email_word_dict.items()]\n",
    "            \n",
    "len(spam_emails_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "027204e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3672"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a vector of words for each ham email\n",
    "\n",
    "ham_emails_vectors = {}\n",
    "\n",
    "for file in ham_stemmed:\n",
    "    with open(file) as file:\n",
    "        sentence = file.read()\n",
    "        words = word_tokenize(sentence)\n",
    "        email_word_dict = word_dict.copy()\n",
    "        for word in words:\n",
    "            email_word_dict[word] += 1\n",
    "        \n",
    "        ham_emails_vectors[file] = [value for key, value in email_word_dict.items()]\n",
    "            \n",
    "len(ham_emails_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28652377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have a Eucledian representation of each email in ham_emails_vectors and spam_emails_vectors.\n",
    "#Each email is a  single entry with the email name as key and email vector as the key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e0617",
   "metadata": {},
   "source": [
    "### Developing a Spam Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c1b70",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b83d3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "260c4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_vector =[]\n",
    "for value in spam_emails_vectors.values():\n",
    "    spam_vector.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a4db3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 50540)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_vector = np.array(spam_vector)\n",
    "spam_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e2e0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_vector =[]\n",
    "for value in ham_emails_vectors.values():\n",
    "    ham_vector.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "021596e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3672, 50540)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_vector = np.array(ham_vector)\n",
    "ham_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19ec5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ham and spam will be the count of a word when it is ham or spam respectively( (Y=1|x_i) and (Y=0|x_0))\n",
    "spam = np.zeros((1, 50540))\n",
    "ham = np.zeros((1, 50540))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da8d33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1500):\n",
    "    for j in range(50540):\n",
    "        spam[0, j] += spam_vector[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e49aa58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3672):\n",
    "    for j in range(50540):\n",
    "        ham[0, j] += ham_vector[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b592878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we calculate probabiliy of each word x_i when a message is spam or not.\n",
    "\n",
    "prob_spam_xi = spam/50540\n",
    "prob_ham_xi = ham/50540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b80b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_spam_per_word = np.zeros((1, 50540))\n",
    "prob_ham_per_word = np.zeros((1, 50540))\n",
    "prob_spam = 0.3\n",
    "prob_ham = 0.7\n",
    "for i in range(prob_spam_per_word.shape[1]):\n",
    "    spam_a = (prob_spam_xi[0,i]*prob_spam) \n",
    "    spam_b = spam_a + (prob_ham_xi[0,i]*prob_ham)\n",
    "    spam_c = spam_a/spam_b\n",
    "    \n",
    "    ham_a = (prob_ham_xi[0,i]*prob_ham) \n",
    "    ham_b = ham_a + (prob_spam_xi[0,i]*prob_spam)\n",
    "    ham_c = ham_a/ham_b\n",
    "    \n",
    "    prob_spam_per_word[0,i] = spam_c\n",
    "    prob_ham_per_word[0,i] = ham_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2092d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14898689, 0.09782922, 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_spam_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90ac391e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_spam = np.zeros((spam_vector.shape[0], 1))\n",
    "for t in range(spam_vector.shape[0]):\n",
    "    conditional_prob_spam = prob_spam\n",
    "    conditional_prob_ham = prob_ham\n",
    "    \n",
    "    for i in range(prob_spam_per_word.shape[1]):\n",
    "        if spam_vector[t][i] == 1:\n",
    "            conditional_prob_spam = conditional_prob_spam * prob_spam_per_word[0,i]\n",
    "            conditional_prob_ham = conditional_prob_ham * prob_ham_per_word[0,i]\n",
    "            \n",
    "    if conditional_prob_spam != 0:\n",
    "        prob = conditional_prob_spam / (conditional_prob_spam + conditional_prob_ham) * 100\n",
    "    else:\n",
    "        prob = 0.0\n",
    "    \n",
    "    if prob > 0.5 * 100:\n",
    "        pred_spam[t, 0] = 1  \n",
    "    else:\n",
    "        pred_spam[t, 0] = 0\n",
    "        \n",
    "pred_spam    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad64eb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ham = np.zeros((ham_vector.shape[0], 1))\n",
    "for t in range(ham_vector.shape[0]):\n",
    "    conditional_prob_spam = prob_spam\n",
    "    conditional_prob_ham = prob_ham\n",
    "    \n",
    "    for i in range(prob_ham_per_word.shape[1]):\n",
    "        if ham_vector[t][i] == 1:\n",
    "            conditional_prob_spam = conditional_prob_spam * prob_spam_per_word[0,i]\n",
    "            conditional_prob_ham = conditional_prob_ham * prob_ham_per_word[0,i]\n",
    "            \n",
    "    if conditional_prob_spam != 0:\n",
    "        prob = conditional_prob_spam / (conditional_prob_spam + conditional_prob_ham) * 100\n",
    "    else:\n",
    "        prob = 0.0\n",
    "    \n",
    "    if prob > 0.5 * 100:\n",
    "        pred_ham[t, 0] = 1 \n",
    "    else:\n",
    "        pred_ham[t, 0] = 0\n",
    "        \n",
    "pred_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2615801e",
   "metadata": {},
   "source": [
    "#### k nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28800d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14898689, 0.09782922, 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_spam_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d293b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85101311, 0.90217078, 0.        , ..., 1.        , 1.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_ham_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b484784a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 50540)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate manhattan distance\n",
    "man_dist = np.abs(spam_vector - prob_spam_per_word)\n",
    "man_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8355156a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65113103],\n",
       "       [0.6505021 ],\n",
       "       [0.65033063],\n",
       "       ...,\n",
       "       [0.65007533],\n",
       "       [0.65013028],\n",
       "       [0.65158603]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan_sum = np.zeros((1500,1))\n",
    "for j in range(1500):\n",
    "    manhattan_sum[j, 0] = man_dist[j].sum()\n",
    "    \n",
    "manhattan_sum/50540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8040f933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3672, 50540)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man_dist = np.abs(ham_vector - prob_ham_per_word)\n",
    "man_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afe65562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34999635],\n",
       "       [0.37432886],\n",
       "       [0.34996341],\n",
       "       ...,\n",
       "       [0.34988539],\n",
       "       [0.35262034],\n",
       "       [0.35346798]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan_sum_ham = np.zeros((3672,1))\n",
    "for j in range(3672):\n",
    "    manhattan_sum_ham[j, 0] = man_dist[j].sum()\n",
    "    \n",
    "manhattan_sum_ham/50540"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2db21ff",
   "metadata": {},
   "source": [
    "####  Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bc05292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "k_neigh_manhattan_pred_ham = np.zeros((3672, 1))\n",
    "for i in range(3672):\n",
    "    if (manhattan_sum_ham/50540)[i] >= 0.5:\n",
    "        k_neigh_manhattan_pred_ham[i] = 1\n",
    "    else:\n",
    "        k_neigh_manhattan_pred_ham[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8270878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "k_neigh_manhattan_pred_spam = np.zeros((1500, 1))\n",
    "for i in range(1500):\n",
    "    if (manhattan_sum/50540)[i] >= 0.5:\n",
    "        k_neigh_manhattan_pred_spam[i] = 1\n",
    "    else:\n",
    "        k_neigh_manhattan_pred_spam[i] = 0\n",
    "        \n",
    "k_neigh_manhattan_pred_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d8ca7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Spam Prediction Accuracy:  [94.46666667]\n",
      "Naive Bayes Ham Prediction Accuracy:  [100.]\n"
     ]
    }
   ],
   "source": [
    "#naive bayes\n",
    "print(\"Naive Bayes Spam Prediction Accuracy: \",(sum(pred_spam)/1500) * 100)\n",
    "print(\"Naive Bayes Ham Prediction Accuracy: \",100 - (sum(pred_ham)/3672) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ac28a533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Neighbors Spam Prediction Accuracy:  [100.]\n",
      "K Neighbors Ham Prediction Accuracy:  [100.]\n"
     ]
    }
   ],
   "source": [
    "print(\"K Neighbors Spam Prediction Accuracy: \",(sum(k_neigh_manhattan_pred_spam)/1500) * 100)\n",
    "print(\"K Neighbors Ham Prediction Accuracy: \",100 - (sum(k_neigh_manhattan_pred_ham)/3672) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2bcbbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above show the train accuracy.The naive bayes has a better confediantilty in its result as compared to k neighbors but \n",
    "# k neighbors has a general better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df64dfca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
